{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import pandas as pd \n",
    "import re\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isEnglish(s):\n",
    "    \"\"\"Takes a token and checks if the input token is english or other language\n",
    "        Input (str): input token\n",
    "        output (bool): true if english else false\"\"\"\n",
    "    try:\n",
    "        s.encode(encoding='utf-8').decode('ascii')\n",
    "    except UnicodeDecodeError:\n",
    "        return bool(re.findall('[A-Za-z]', s))\n",
    "    else:\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(filename):\n",
    "    data = pd.read_csv(filename, encoding ='utf-16')\n",
    "    data = data[['date', 'author','title', 'content']]\n",
    "    data = data.drop_duplicates()\n",
    "    data.to_csv(filename, header=['date', 'author','title', 'content'], encoding=\"utf-16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = list()\n",
    "url_list.append({\"url\":\"https://ecadforum.com/Amharic/archives/%s/\", \"max_page\":19743}) # 1124\n",
    "\n",
    "def spiderECADF(max_pages, page_url, cookies=None):\n",
    "    data = list()\n",
    "    for i in tqdm(range(3879, max_pages)):\n",
    "        url = page_url%i\n",
    "        if cookies != None:\n",
    "            crawl_url = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}, cookies=cookies)\n",
    "        else:\n",
    "            crawl_url = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "            \n",
    "        if crawl_url.status_code == 404:\n",
    "            continue\n",
    "        soup = BeautifulSoup(crawl_url.text, 'lxml')\n",
    "        body = soup.find(\"div\", class_=\"post-inner\")\n",
    "        if body == None:\n",
    "            continue\n",
    "        title = body.h1.text\n",
    "        title = \" \".join(title.split())\n",
    "        content = \" \".join(s for s in body.find(\"div\", class_=\"entry\").text.split() if not isEnglish(s))\n",
    "        meta_data = body.find(\"p\", class_=\"post-meta\")\n",
    "        if meta_data != None:\n",
    "            author = meta_data.find(\"span\", class_=\"post-meta-author\").text\n",
    "            date = meta_data.find(\"span\", class_=\"tie-date\").text\n",
    "        else:\n",
    "            author, date = None, None\n",
    "        data.append([date, author, title, content])\n",
    "        df = pd.DataFrame(data, columns = ['date', 'author', 'title', 'content'])\n",
    "        df = df[['date', 'author','title', 'content']]       \n",
    "        out_file = 'ECADF_amharic.csv' \n",
    "        if i % 100:\n",
    "            # if file does not exist write header            \n",
    "            if not os.path.isfile(out_file):\n",
    "                df.to_csv(out_file, header=['date', 'author','title', 'content'], encoding=\"utf-16\")\n",
    "            else: # else it exists so append without writing the header\n",
    "                df.to_csv(out_file, mode='a', header=False, encoding=\"utf-16\")\n",
    "        if i%500:\n",
    "            remove_duplicates(out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████████▋                                                              | 2320/15864 [1:03:17<6:29:17,  1.72s/it]"
     ]
    }
   ],
   "source": [
    "for site in url_list:\n",
    "    spiderECADF(site['max_page'], site['url'])\n",
    "    \n",
    "#     df = pd.DataFrame(data, columns =['title', 'content']) \n",
    "#     df.to_csv(\"ESAT_\"+site['category']+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"ECADF_amharic.csv\", encoding ='utf-16')\n",
    "data = data[['date', 'author','title', 'content']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>April 26, 2011</td>\n",
       "      <td>Posted by: ecadforum</td>\n",
       "      <td>“እኔ ያመጣሁት የአቋምም ሆነ የአቋቋም ለውጥ የለም” አቤ ቶኪቻው</td>\n",
       "      <td>“እኔ ያመጣሁት የአቋምም ሆነ የአቋቋም ለውጥ የለም” አቤ ቶኪቻው ቀደም ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>April 26, 2011</td>\n",
       "      <td>Posted by: ecadforum</td>\n",
       "      <td>“እኔ ያመጣሁት የአቋምም ሆነ የአቋቋም ለውጥ የለም” አቤ ቶኪቻው</td>\n",
       "      <td>“እኔ ያመጣሁት የአቋምም ሆነ የአቋቋም ለውጥ የለም” አቤ ቶኪቻው ቀደም ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>May 8, 2011</td>\n",
       "      <td>Posted by: ecadforum</td>\n",
       "      <td>ኢትዮጵያዊው ሞሃመድ ቡኣዚዝ</td>\n",
       "      <td>ፍቅር ይበልጣል የዐረቡን ዓለም በማንቀጥቀጥ ላይ የሚገኘውን ሕዝባዊ አመፅ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>April 26, 2011</td>\n",
       "      <td>Posted by: ecadforum</td>\n",
       "      <td>“እኔ ያመጣሁት የአቋምም ሆነ የአቋቋም ለውጥ የለም” አቤ ቶኪቻው</td>\n",
       "      <td>“እኔ ያመጣሁት የአቋምም ሆነ የአቋቋም ለውጥ የለም” አቤ ቶኪቻው ቀደም ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>May 8, 2011</td>\n",
       "      <td>Posted by: ecadforum</td>\n",
       "      <td>ኢትዮጵያዊው ሞሃመድ ቡኣዚዝ</td>\n",
       "      <td>ፍቅር ይበልጣል የዐረቡን ዓለም በማንቀጥቀጥ ላይ የሚገኘውን ሕዝባዊ አመፅ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date                 author  \\\n",
       "0  April 26, 2011  Posted by: ecadforum    \n",
       "1  April 26, 2011  Posted by: ecadforum    \n",
       "2     May 8, 2011  Posted by: ecadforum    \n",
       "3  April 26, 2011  Posted by: ecadforum    \n",
       "4     May 8, 2011  Posted by: ecadforum    \n",
       "\n",
       "                                       title  \\\n",
       "0  “እኔ ያመጣሁት የአቋምም ሆነ የአቋቋም ለውጥ የለም” አቤ ቶኪቻው   \n",
       "1  “እኔ ያመጣሁት የአቋምም ሆነ የአቋቋም ለውጥ የለም” አቤ ቶኪቻው   \n",
       "2                          ኢትዮጵያዊው ሞሃመድ ቡኣዚዝ   \n",
       "3  “እኔ ያመጣሁት የአቋምም ሆነ የአቋቋም ለውጥ የለም” አቤ ቶኪቻው   \n",
       "4                          ኢትዮጵያዊው ሞሃመድ ቡኣዚዝ   \n",
       "\n",
       "                                             content  \n",
       "0  “እኔ ያመጣሁት የአቋምም ሆነ የአቋቋም ለውጥ የለም” አቤ ቶኪቻው ቀደም ...  \n",
       "1  “እኔ ያመጣሁት የአቋምም ሆነ የአቋቋም ለውጥ የለም” አቤ ቶኪቻው ቀደም ...  \n",
       "2  ፍቅር ይበልጣል የዐረቡን ዓለም በማንቀጥቀጥ ላይ የሚገኘውን ሕዝባዊ አመፅ...  \n",
       "3  “እኔ ያመጣሁት የአቋምም ሆነ የአቋቋም ለውጥ የለም” አቤ ቶኪቻው ቀደም ...  \n",
       "4  ፍቅር ይበልጣል የዐረቡን ዓለም በማንቀጥቀጥ ላይ የሚገኘውን ሕዝባዊ አመፅ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2396"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('ECADF_amharic.csv', header=['date', 'author','title', 'content'], encoding=\"utf-16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
